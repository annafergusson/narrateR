---
title: "narrater"
output: 
  html_document:
    df_print: paged
    self-contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# You'll need to set up your Amazon credentials to use aws.polly
# see https://github.com/cloudyr/aws.signature/
# Sys.setenv("AWS_ACCESS_KEY_ID" = "",
#          "AWS_SECRET_ACCESS_KEY" = "",
#          "AWS_DEFAULT_REGION" = "")

# reset WAV count - there must be a better way...
wav_count <- 0
# unlink("narrations/*") 
# ???
```

```{r my_functions, echo=FALSE}
# function to create wav narration files
createNarration <- function(text, 
                            voice = "Nicole"){
  voice_file <- aws.polly::synthesize(text, voice = voice)
  wav_count <<- wav_count + 1
  file_name <- glue::glue("narration{wav_count}.wav")
  tuneR::writeWave(voice_file,
                   file = glue::glue("narrations/{file_name}"))
  return(glue::glue("narrations/{file_name}"))
}


# function to create a narration text
addNarrationText <- function(text, 
                               voice = "Nicole", 
                               display_text){
  soundFile <- createNarration(text, voice)
  return(htmltools::tags$span(display_text, 
                       onclick = glue::glue("playSound('{soundFile}')"),
                       title = text,
                       class = "narrate"))
}

# function to create a narration button
addNarrationButton <- function(text, 
                               voice = "Nicole", 
                               button_text){
  soundFile <- createNarration(text, voice)
  return(htmltools::tags$button(button_text, 
                       onclick = glue::glue("playSound('{soundFile}')"),
                       title = text,
                       class = "narrate"))
}

# function to create a narration image
addNarrationImage <- function(text, 
                               voice = "Nicole", 
                               image, 
                               width = '100%'){
  soundFile <- createNarration(text, voice)
  return(htmltools::tags$a(htmltools::tags$img(src=image, width=width), 
                        onclick = glue::glue("playSound('{soundFile}')"),
                        title = text, 
                        class = "narrate"))
}
```

```{r button_demo, echo=FALSE}
text <- "I want to create this package for two reasons: one, my students get stressed out when they see lots of text on a page, including code, so I want a way to reduce the amount of text used but still be able to communicate or describe ideas. And two, I want to be able to model reading the code for students even if I am not able to do this in person beside them at their computer! Try clicking on some of the things below"

addNarrationButton(text = text, 
                   button_text = "Tell me more about the idea for this package!")
```


```{r image_demo, echo=FALSE}
text <- "You could attach narration to images, like my cute stats cat Elliot."

addNarrationImage(text = text,
                  image = 'logo.png', 
                  width = '100')
```

```{r plot_demo, echo=FALSE}
library(ggplot2)
data("iris")
p <- ggplot(data = iris) +
  geom_point(aes(x = Sepal.Length, y = Sepal.Width))
ggsave(plot = p, "iris.png")

text <- "And add narration to plots, like to say .. oh hey, iris data, aren't you suu-per interesting?"

addNarrationImage(text = text,
                  image = 'iris.png',
                  width = '80%')
```

::: {#code_demo}
```{r code_demo, class.source='narrate'}
library(readr)
read_csv('anna.csv')
```
:::

```{r echo = FALSE}
text <- 'And demonstrate reading code, for example, the read c s v function from the package read arrr will read the contents of the anna dot c s v file into a dataframe'

# hardcoded for now
file_name <- createNarration(text, 
                            voice = "Nicole")
```

```{js echo = FALSE}
$().ready(function(){

  //add a div with id "sounds"
  var elem = document.createElement('div');
  elem.id = "sounds";
  document.body.appendChild(elem);
  
  //change some of the css
  $("a.narrate").css({"pointer-events": "auto"});
  $("span.narrate").hover(function() {
    $(this).css("cursor","pointer");
    $(this).css("background-color","#c0c0c0");
  });
  $("a.narrate").hover(function() {
    $(this).css("cursor","pointer");
  });
  $("button.narrate").hover(function() {
    $(this).css("cursor","pointer");
  });
   $("pre.narrate").hover(function() {
    $(this).css("cursor","pointer");
  });
  
  //hardcoded
  $("#code_demo").attr('onClick','playSound("narrations/narration4.wav")');
})

function playSound(file_src) {
  document.getElementById("sounds").innerHTML = '<audio id="audio" src=' + file_src + ' autoplay="false" ></audio>';
  var sound = document.getElementById("audio");
  sound.play();
}
```
	